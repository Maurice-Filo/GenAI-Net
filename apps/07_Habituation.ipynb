{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b2e67e8",
   "metadata": {},
   "source": [
    "# RL4CRN tutorial notebook: Habituation (CVODE)\n",
    "\n",
    "Refer to the Logic Circuits tutorial for more information about the overall pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9411e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, numpy as np\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"CWD:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eced7e13",
   "metadata": {},
   "source": [
    "## 1) Import RL4CRN helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e847044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Dict, List, Sequence, Tuple, Union\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "from RL4CRN.utils.input_interface import (\n",
    "    register_task_kind,\n",
    "    overrides_get,\n",
    "    Configurator,\n",
    "    TaskKindBase,\n",
    "    TaskSpec,\n",
    ")\n",
    "\n",
    "from RL4CRN.utils.default_tasks.HabituationTaskKind import HabituationGapTaskKind\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4259f10e",
   "metadata": {},
   "source": [
    "## 2) Build a template IO/CRN\n",
    "\n",
    "Here we use the convenience builder `build_simple_IOCRN`, which provides an easy way to construct a I/O CRNs specifying dictionaries for input and output nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9e7ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RL4CRN.utils.crn_builders import build_simple_IOCRN\n",
    "\n",
    "# choose preset\n",
    "cfg = Configurator.preset(\"paper\")\n",
    "\n",
    "# select simulator and set tolerances\n",
    "cfg.solver.algorithm = \"CVODE\"\n",
    "cfg.solver.rtol = 1e-10\n",
    "cfg.solver.atol = 1e-10\n",
    "\n",
    "# build template IO/CRN\n",
    "species_labels = ['X_1', 'X_2', 'X_3']\n",
    "crn, species_labels = build_simple_IOCRN(\n",
    "    species=species_labels,\n",
    "    production_input_map={\"X_1\": \"u_1\"},\n",
    "    degradation_input_map={},\n",
    "    dilution_map={\"X_1\": 0.1, \"X_2\": 0.1, \"X_3\": 0.1},  # add dilution to ensure steady state exists\n",
    "    production_map={\"X_2\": 0.1},  # add basal production to X_2 nonzero peaks\n",
    "    output_species=\"X_3\",\n",
    "    solver=cfg.solver,\n",
    ")\n",
    "\n",
    "print(\"Template CRN built.\")\n",
    "print(\" - num_inputs:\", crn.num_inputs)\n",
    "print(\" - num_species:\", len(species_labels))\n",
    "print(\" - species:\", species_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5afb5ec",
   "metadata": {},
   "source": [
    "## 3) Build the reaction library (MAK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4accb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RL4CRN.utils.library_builders import build_MAK_library\n",
    "\n",
    "# library components\n",
    "library_components = build_MAK_library(crn, species_labels, order=2)\n",
    "\n",
    "library, M, K, masks = library_components\n",
    "print(\"Library built.\")\n",
    "print(\" - M (num reactions in library):\", M)\n",
    "print(\" - K (num parameters in library):\", K)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc96f08",
   "metadata": {},
   "source": [
    "## 4) Define the task: RPA\n",
    "\n",
    "- `kind=\"oscillator_mean\"` selects the reward handler.\n",
    "- `ic=(\"constant\", 0.01)` sets initial concentrations.\n",
    "- we use `u_values` to identify the combinations between input and disturbance\n",
    "- we use `targets` to highlight the target output we seek to reach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad481290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RL4CRN.utils.input_interface import get_task_kind\n",
    "get_task_kind(\"habituation\").pretty_help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4543740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RL4CRN.utils.input_interface import make_task, print_task_summary\n",
    "\n",
    "task = make_task(\n",
    "    template_crn=crn,\n",
    "    library_components=library_components,\n",
    "    kind=\"habituation\",\n",
    "    species_labels=species_labels,\n",
    "    params={\n",
    "        \"pulse_shape\": (1,9),\n",
    "        \"n_repeats\": 10,\n",
    "        \"n_t\": 1000,\n",
    "        \"ic\": \"from_ss\",  # use steady-state ICs for each input\n",
    "        \"weights\": \"transient\",\n",
    "        \"max_peak\": 10.0,\n",
    "        \"u_values\": [1.0], # the product (per input) of all the combinations of these values will be used \n",
    "    }\n",
    ")\n",
    "\n",
    "print_task_summary(task)\n",
    "\n",
    "# --- Optional safety checks (recommended) ---\n",
    "print(\"Sanity checks:\")\n",
    "print(\" - template num_inputs:\", crn.num_inputs)\n",
    "print(\" - first u shape:\", np.asarray(task.u_list[0]).shape)\n",
    "print(\" - first u length:\", len(task.u_list[0]))\n",
    "assert len(task.u_list[0]) == crn.num_inputs, \"Input dimension mismatch: u has wrong length!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8197f053",
   "metadata": {},
   "source": [
    "## 5) Training configuration\n",
    "\n",
    "We tune:\n",
    "- `max_added_reactions`: episode length (how many reactions the agent can add)\n",
    "- `epochs`: training iterations\n",
    "- `render_every`: print progress cadence\n",
    "- `seed`: reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a716913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Train config ----\n",
    "cfg.train.max_added_reactions = 5\n",
    "cfg.train.epochs = 100\n",
    "cfg.train.render_every = 5\n",
    "cfg.train.seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10455463",
   "metadata": {},
   "source": [
    "Rendering options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb5572",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.render.n_best = 100\n",
    "cfg.render.disregarded_percentage = 0.9\n",
    "cfg.render.mode = {  # Mode of the experiment\n",
    "    'style': 'logger', \n",
    "    'task': 'habituation', \n",
    "    'format': 'image',\n",
    "    'topology': True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a68585",
   "metadata": {},
   "source": [
    "## 6) Inspect full configuration (optional)\n",
    "\n",
    "`cfg.describe()` prints a nested configuration dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212bec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ea5145",
   "metadata": {},
   "source": [
    "## 7) Create session + trainer\n",
    "\n",
    "This step wires together:\n",
    "- parallel environments\n",
    "- observer/tensorizer/actuator/stepper interfaces\n",
    "- policy + agent\n",
    "- the chosen task reward function\n",
    "\n",
    "The returned object:\n",
    "- `trainer`: runs rollout → reward eval → policy update loops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bfebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pytorch_lightning.loggers import CometLogger\n",
    "\n",
    "task_name = \"Habituation_h1_Task\"\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# Expect these in your environment:\n",
    "#   COMET_API_KEY   (required)\n",
    "#   COMET_WORKSPACE (required)\n",
    "api_key = os.environ[\"COMET_API_KEY\"]\n",
    "workspace = os.environ[\"COMET_WORKSPACE\"]\n",
    "\n",
    "logger = CometLogger(\n",
    "    api_key=api_key,\n",
    "    project=task_name,\n",
    "    workspace=workspace,\n",
    "    name=f\"{task_name}_{timestamp}\",\n",
    ")\n",
    "\n",
    "logger = logger.experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d9144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RL4CRN.utils.input_interface import make_session_and_trainer\n",
    "trainer = make_session_and_trainer(cfg, task, logger=logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0c759a",
   "metadata": {},
   "source": [
    "## 8) Train and save checkpoints\n",
    "\n",
    "We run for `cfg.train.epochs` epochs and periodically save a checkpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7019b24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"habituation_task_chkpt.pkl\"\n",
    "trainer.run(epochs=cfg.train.epochs, checkpoint_path=checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9912ffe9",
   "metadata": {},
   "source": [
    "## 9) Inspect the best CRN\n",
    "\n",
    "The trainer keeps a **Hall of Fame** of good CRNs found during rollouts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5204c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.inspect_best(plot=True)\n",
    "\n",
    "best = trainer.best_crn()\n",
    "print(\"Hall of Fame size:\", len(trainer.s.mult_env.hall_of_fame))\n",
    "if best is not None:\n",
    "    print(\"Best loss:\", best.last_task_info.get(\"reward\", None))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5c8ffe",
   "metadata": {},
   "source": [
    "## 10) Sample and re-simulate\n",
    "\n",
    "After training, we can **draw new CRN designs from the learned policy** (sampling runs in evaluation mode, i.e., no gradient updates) and **re-evaluate** them.\n",
    "\n",
    "This is useful for:\n",
    "- **Model exploration:** quickly inspect diverse candidates generated by the policy.\n",
    "- **Controlled re-simulation:** re-run sampled CRNs under modified conditions (`u_list/u_spec`, `ic`, etc.).\n",
    "\n",
    "Sampling produces a dedicated **sample Hall-of-Fame** that stores the best `K` sampled environments (lowest loss) for later inspection and checkpointing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f07be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.sample(10, 10, ic=(\"constant\", 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf9e2f0",
   "metadata": {},
   "source": [
    "We can now inspect newly sampled I/O CRNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16990b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = 0\n",
    "crn_s = trainer.get_sampled_crns()[index]\n",
    "print(crn_s)\n",
    "print(\"reward:\", crn_s.last_task_info.get(\"reward\", None))\n",
    "\n",
    "# Plotters depend on your IOCRN implementation\n",
    "crn_s.plot_transient_response(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a81770",
   "metadata": {},
   "source": [
    "Save again our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73df5e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f5203a",
   "metadata": {},
   "source": [
    "## 11) Loading a saved Session/Trainer from a checkpoint\n",
    "\n",
    "`load_session_and_trainer` reconstructs wiring and restores weights, history, HoFs, and RNG states.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7930bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RL4CRN.utils.input_interface import load_session_and_trainer\n",
    "\n",
    "trainer_loaded = load_session_and_trainer(checkpoint_path, device=\"cuda\")\n",
    "trainer_loaded.inspect_best()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4281c6d",
   "metadata": {},
   "source": [
    "## 12) Re-simulate Hall-of-Fame CRNs under new conditions\n",
    "\n",
    "We can take the training Hall-of-Fame CRNs and re-simulate them under a new IC and/or new input set.\n",
    "\n",
    "This uses `Trainer.resimulate(...)` which clones CRNs before evaluation (so old results remain intact).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454868a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hof_crns = [item.state for item in trainer.s.mult_env.hall_of_fame]\n",
    "\n",
    "trainer.s.crn_template\n",
    "\n",
    "crns_new = trainer.resimulate(\n",
    "    hof_crns,\n",
    ")\n",
    "\n",
    "trainer.inspect(crns_new[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
